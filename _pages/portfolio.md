---
layout: archive
title: "Portfolio"
permalink: /portfolio/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}



<hr style="margin:0;padding:0; height:4px;background-color: #696969;">

<a href="https://psyarxiv.com/7enqw/">
	<img align="right" src="../files/PsyArXiv_logo.png" style="height:3em">
</a>
<h2 style="font-size:2em;">Predicting pandemic mental health outcomes</h2>

<img src="../files/covid19_fig.png" width="55%" style="margin: 0em 0em 0em 0em; " align="right">
<p style="font-size:16px;padding:0;margin:0;margin-bottom:1em">The “Mental Health Impact of COVID-19 Pandemic on NIMH Patients and Volunteers” study was a longitudinal study launched in spring 2020 by researchers at NIMH, to investigate the effect of the emerging COVID-19 pandemic on mental health. For each participant, the study collected personal characteristics, such as demographics, psychological traits, and clinical history, together with personal circumstances at regular intervals during their enrollment in the study. In this paper, we examine the degree to which a variety of mental health outcomes over time for an individual can be predicted from personal characteristics and their changing circumstances, using regression models trained on other study participants. We find that it is possible to predict the variation of a participant's mental health outcomes from time point to time point, for most of the outcomes we consider. This capability is dominated by information about outcome at the point of enrollment in the study, but can be improved by considering personal characteristics and circumstances.</p>

<hr style="margin:0;padding:0; height:4px;background-color: #696969;">

<a href="https://github.com/carlwharris/nwb-photostim">
	<img align="right" src="../files/GitHub_logo.png" style="height:3em">
</a>
<h2 style="font-size:2em;">Holographic photostimulation extension</h2>

<img src="../files/nwb_overview.png" width="45%" style="margin: 0em 0em 0em 0em; " align="right">
<p style="font-size:16px;padding:0;margin:0;margin-bottom:1em">State-of-the-art <a href="https://www.nature.com/articles/s41467-017-01031-3">holographic photostimulation methods</a>, used in concert with <a href="https://www.nature.com/articles/nmeth818">two-photon imaging</a>, 
allow unprecedented 
control and measurement of cell activity in the living brain. Methods for managing data for two-photon imaging 
experiments are improving, but there is little to no standardization of data for holographic stimulation methods. 
Stimulation in vivo depends on fine-tuning many experimental variables, which poses a challenge for reproducibility 
and data sharing between researchers. To improve <a href="https://www.sciencedirect.com/science/article/pii/S0896627321009557">standardization</a> of photostimulation data storage and processing, 
we release this extension as a generic data format for simultaneous holographic stimulation experiments, 
using the <a href="https://www.nwb.org/">NeuroData Without Borders (NWB)</a> format for neurophysiology data to store experimental details and data relating to both acquisition 
and photostimulation. It includes <a href="https://pynwb.readthedocs.io/en/stable/">containers</a> for storing photostimulation-specific device parameters, holographic patterns (either 2D or 3D), and time series data related to photostimulation. This project is part of an ongoing intra-NIMH collaboration between <a href="https://markhisted.org/">Mark Histed's lab</a> and the <a href="https://cmn.nimh.nih.gov/dsst">Data Science and Sharing Team</a>.</p>

<hr style="margin:0;padding:0; height:4px;background-color: #696969;">

<a href="https://arxiv.org/abs/2211.09295">
	<img align="right" src="../files/arxiv-logo-1.png" style="height:2.5em">
</a>
<h2 style="font-size:2.5em;">Context-dependent encoding</h2>

<img src="../files/boxplots_v2.png" width="35%" style="margin: 0em 0em 0em 0em; " align="right">
<p style="font-size:16px;padding:0;margin:0;margin-bottom:1em">We propose a decoding-based approach to detect context effects on neural codes in longitudinal neural recording data. The approach is agnostic to how information is encoded in neural activity, and can control for a variety of possible confounding factors present in the data. We demonstrate our approach by determining whether it is possible to decode location encoding from prefrontal cortex in the mouse and, further, testing whether the encoding changes due to task engagement.</p>


<hr style="margin:0;padding:0; height:4px;background-color: #696969;">

<!--
<a href="https://www.biorxiv.org/content/10.1101/2022.06.20.496909v1" style="float:right;">
	<img align="right" src="https://www.biorxiv.org/sites/default/files/site_logo/bioRxiv_logo_homepage.png" style="height:2.5em;padding-left:1em">
</a>
<a href="https://github.com/carlwharris/DeepAction" style="float:right">
	<img align="right" src="../files/GitHub_logo.png" style="height:2.5em;">
</a>
<h2 style="font-size:2.5em;">DeepAction Toolbox</h2>

<table width="100%" style="border:none;margin:0;padding:0">
<td style="border:none;padding:0px;margin:0;" width="70%" align="left">
	<h2 style="font-size:2.5em;">DeepAction Toolbox</h2>
</td>
<td style="border:none;padding:0px;margin:0;"  align="right">
	<a href="https://www.biorxiv.org/content/10.1101/2022.06.20.496909v1">
		<img align="center" src="https://www.biorxiv.org/sites/default/files/site_logo/bioRxiv_logo_homepage.png" style="height:2.5em;margin-top:-1em"></a>
	&nbsp;&nbsp;
	<a href="https://github.com/carlwharris/DeepAction"><img align="center" src="../files/GitHub_logo.png" style="height:2.5em;margin-top:-1em">
	</a>
</td>
</table>
-->
<div style="clear: both;">
  <div style="float: right;vertical-align: middle;">
    <a href="https://www.biorxiv.org/content/10.1101/2022.06.20.496909v1">
	<img src="https://www.biorxiv.org/sites/default/files/site_logo/bioRxiv_logo_homepage.png" style="height:2.5em;">
	</a>
	&nbsp;&nbsp;
    <a href="https://github.com/carlwharris/DeepAction" >
		<img align="right" src="../files/GitHub_logo.png" style="height:2.5em;">
	</a>
  </div>
  <div>
    <h2 style="font-size:2.5em;">DeepAction Toolbox</h2>
  </div>
  
 <table width="50%" align="right">
	<tr style="width:100%;border:none;margin:0;padding:0;">
		<td style="border:none;padding:0.2em" width="33%">
			<img src="../files/home_cage_50.gif" style="max-width:100%;height:auto;">
		</td>
		<td style="border:none;padding:0.2em" width="33%">
			<img src="../files/CRIM13S-785.gif" style="max-width:100%;height:auto;">
		</td>						
		<td style="border:none;padding:0.2em" width="33%">
			<img src="../files/CRIM13T-203.gif" style="max-width:100%;height:auto;">
		</td>
	</tr>
	<tr style="width:100%;border:none;margin:0;padding:0;">
		<td style="border:none;padding:0.2em;" width="33%">
			<img src="../files/home_cage_182.gif" style="max-width:100%;height:auto;">
		</td>
		<td style="border:none;padding:0.2em" width="33%">
			<img src="../files/CRIM13S-1785.gif" style="max-width:100%;height:auto;">
		</td>						
		<td style="border:none;padding:0.2em" width="33%">
			<img src="../files/CRIM13T-256.gif" style="max-width:100%;height:auto;">
		</td>
	</tr>
</table>
<p style="font-size:16px">In this project, I created a MATLAB toolbox for automated classification of animal in behavior. It uses features extracted from raw video frames to train a bidirectional LSTM classifier, which in addition to predicting behavior generates a confidence score for the predicted label. These confidence scores allow for the selective review and correction of ambiguous annotations while omitting unnecessary review.</p>

<br>
<hr style="height:4px;background-color: #696969;">

<a href="https://github.com/carlwharris/Discovery-DLC-processing">
	<img align="right" src="../files/GitHub_logo.png" style="height:2.5em">
</a>
<h2 style="font-size:2.5em;">HPC keypoint extraction</h2>


<img src="../files/pipeline_diagram.png" align="right" style="width:60%;">
<p style="font-size:16px;">We propose a decoding-based approach to detect context effects on neural codes in longitudinal neural recording data. The approach is agnostic to how information is encoded in neural activity, and can control for a variety of possible confounding factors present in the data. We demonstrate our approach by determining whether it is possible to decode location encoding from prefrontal cortex in the mouse and, further, testing whether the encoding changes due to task engagement.</p>



<hr style="height:4px;background-color: #696969;">


<a href="https://github.com/carlwharris/elliptic-curve-cryptosystems">
	<img align="right" src="../files/GitHub_logo.png" style="height:2.5em">
</a>
<h2 style="font-size:2.5em;">Elliptic curve cryptography</h2>


<img src="../files/ECC.jpeg" align="left" style="width:10%;">
<p style="font-size:16px;">Final project for Abstract Algebra (Dartmouth College, Fall 2020) in which I implemented a simple elliptic curve cryptosystem in MATLAB. The corresponding <a href="https://github.com/carlwharris/elliptic-curve-cryptosystems/blob/main/ECC%20Project%20Paper.pdf">paper</a> includes information about: the invention of public key and elliptic curve cryptography, elliptic curves over finite fields, subgroup generation, and how cryptographic systems are constructed from elliptic curves and used to encrypt and decrypt messages.</p>

<hr style="height:4px;background-color: #696969;">
